
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Xinrui Zu's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Xinrui Zu is currently a research assistant at Department of Imaging Physics, TU Delft">
  <meta name="keywords" content="Xinrui Zu, 祖新瑞, zuxinrui, Xinrui, Zu, Deep Learning, TU Delft, FDU, Computer, Vision, Machine, Learning, Generative, Model, Diffusion">
  <meta name="author" content="Xinrui Zu" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icon.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-dark-grey w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>Xinrui Zu</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#projects" class="w3-bar-item w3-button">Projects</a>
    <a href="#talks" class="w3-bar-item w3-button">Talks</a>
    <a href="#publications" class="w3-bar-item w3-button">Publications</a>
<!--    <a href="#award" class="w3-bar-item w3-button">Awards</a>-->
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">Xinrui</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 70%;max-width: 320px" alt="profile photo" src="images/zuxinrui.png">
      <h1>Xinrui Zu</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am a research assistant at <a href="https://www.tudelft.nl/tnw/over-faculteit/afdelingen/imphys">Department of Imaging Physics, TU Delft</a>, Netherlands, where I am advised by Dr. <a href="https://www.tudelft.nl/tnw/over-faculteit/afdelingen/imphys/about-the-department/tao-qian">Qian Tao</a></a> and working on Generative Models, Unsupervised Learning, Machine Learning theories, etc. I finished my MSc at <a href="https://www.ram.eemcs.utwente.nl">Robotics and Mechatronics group, University of Twente</a>, with my thesis focusing on diffusion-based generative models. I did my bachelors at <a href="https://en.wikipedia.org/wiki/Fudan_University">Fudan University</a>, majored in Theoretical and Applied Mechanics.
        </p>
        <p class="w3-center">
          <a href="mailto:zuxinrui95@gmail.com">Email</a> &nbsp/&nbsp
            <a href="https://www.linkedin.com/in/zuxinrui/">LinkedIn</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=t7rNKqEAAAAJ">Google Scholar</a>
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
<!--      <p><li> 12/2023, MSc thesis accepted. <a style="color: #447ec9" href="https://essay.utwente.nl/95061/">[Paper]</a></li></p>-->
      <p><li> 04/2024, One short paper has been accepted by <a href="https://www.midl.io/">MIDL 2024</a>. <a style="color: #447ec9" href="https://openreview.net/forum?id=orIWvvBK2v">[Paper]</a></li></p>
      <p><li> 05/2023, MSc thesis accepted. <a style="color: #447ec9" href="https://essay.utwente.nl/95061/">[Paper]</a></li></p>
      <p><li> 05/2022, One paper has been accepted by <a href="https://icml.cc/">ICML 2022</a>. <a style="color: #447ec9" href="https://proceedings.mlr.press/v162/zu22a.html">[Paper]</a> | <a style="color: #447ec9" href="https://slideslive.com/38983456/spacemap-visualizing-highdimensional-data-by-space-expansion">[Video]</a> | <a style="color: #447ec9" href="https://github.com/zuxinrui/SpaceMAP">[Code]</a> </li></p>
      <p><li> 01/2022, One journal paper has been accepted by <a href="https://openaccess.thecvf.com/CVPR2022">IEEE TVCG</a>. <a style="color: #447ec9" href="https://ieeexplore.ieee.org/document/9585419">[Paper]</a> | <a style="color: #447ec9" href="https://github.com/zuxinrui/DeepRecursiveEmbedding">[Code]</a> </li></p>
  </div>

<!-- The Projects Section -->
  <div class="w3-container w3-padding-32" id="projects">
    <h2>Recent Projects</h2>
    <p class="w3-justify">
<!--      These are my on-going and previous projects. I've always love robot combining useful learning algorithms and elegent control theories. Perception, recognition and control are three main modules of robotics and I desire to contruct them organically in order to build fancy robots. With the deep thought about dynamics in control theory and the innovative ideas in learning algorithm, building such robots is like cooking, machine learning spreads fancinating smell to attract me to dive into this area, and control theory provides excellent flavor to make me love the elegence of robotics.-->
      These projects are sorted by time.
    </p>
      <hr class="divider" />
        <h3><li><strong>Contrastive Optimal Transport Flow (under review)</strong> </li></h3>
      <p class="w3-justify">
          Our proposed generative framework (COT Flow) achieves fast and high-quality generation with improved zero-shot editing flexibility compared to previous diffusion models (under review).
        </p>
      <p class="w3-justify">
          Unpaired image-to-image translation:
        </p>
<!--        <img style="width: 16%;" src="images/COT/1.gif"> <img style="width: 16%;" src="images/COT/2.gif"> <img style="width: 16%;" src="images/COT/3.gif"> <img style="width: 16%;" src="images/COT/4.gif"> <img style="width: 16%;" src="images/COT/5.gif"> <img style="width: 16%;" src="images/COT/6.gif">-->
        <img style="width: 24%;" src="images/COT/cotflow-i2i-h2s.gif"> <img style="width: 24%;" src="images/COT/cotflow-i2i-m2f.gif"> <img style="width: 24%;" src="images/COT/cotflow-i2i-o2c.gif"> <img style="width: 24%;" src="images/COT/cotflow-i2i-e2m.gif">
      <p class="w3-justify">
          Zero-shot image editing scenarios. 1. Image composition:
        </p>
      <p class="w3-justify w3-center">
        <img style="width: 60%;" src="images/COT/cotflow-composition-1.gif">
      <img style="width: 60%;" src="images/COT/cotflow-composition-2.gif">
      <img style="width: 60%;" src="images/COT/cotflow-composition-3.gif">
        </p>
      <p class="w3-justify">
          2. Stroke-texture coupling:
        </p>
      <img style="width: 100%;" src="images/COT/cotflow-coupling-1.gif">
      <img style="width: 100%;" src="images/COT/cotflow-coupling-2.gif">
      <img style="width: 100%;" src="images/COT/cotflow-coupling-3.gif">
      <p class="w3-justify">
          3. Zero-shot image augmentation:
        </p>
      <img style="width: 100%;" src="images/COT/cotflow-augmentation.gif">

      <hr class="divider" />

        <h3><li><strong>cHeartFlow: Synthesizing Cardiac MR Images from Sketches</strong> <a style="color: #447ec9" href="https://openreview.net/forum?id=orIWvvBK2v">[Paper]</a></li></h3>
      <p class="w3-justify">
          We present contrastive HeartFlow (cHeartFlow), a novel generative framework to synthesize cardiac magnetic resonance (CMR) images from simple sketches by training on contrastive pairs of images and sketches.
        </p>
      <p class="w3-justify">
          cHeartFlow generation compared with popular GAN-based and diffusion-based models:
        </p>
        <p style="text-align:center;">
            <img style="width:100%;" src="images/Fig1_v4.png">
            </p>
      <p class="w3-justify">
          Zero-shot MRI registration using cHeartFlow with trade-off between registration accuracy (faithfulness) and image quality (realism). The below GIFs: (1) Original MRI cycle. (2) Registration with control parameter t=0.75. (3) t=0.5. (4) t=0.25:
        </p>
      <img style="width: 23%;" src="images/original.gif"> &nbsp <img style="width: 23%;" src="images/seg-t0.25.gif"> &nbsp <img style="width: 23%;" src="images/seg-t0.5.gif"> &nbsp <img style="width: 23%;" src="images/seg-t0.75.gif">
      <p class="w3-justify">
          cHeartFlow overview ((a) training and (b) sampling):
        </p>
        <p style="text-align:center;">
        <img style="width:70%;" src="images/Fig2_v3.png">
        </p>

        <hr class="divider" />

        <h3><li><strong>DiFine UI: Controllable Medical Image Synthesis on the Webpage</strong> </li></h3>
      <p class="w3-justify">
          I developed a web-based medical image synthesis platform called DiFine UI. The platform is based on the proposed model <a style="color: #447ec9" href="https://essay.utwente.nl/95061/">LSDM</a>. The platform allows users to draw any medical images from sketches and control the synthesis by adjusting the diagnosis parameters through our proposed inpainting classifier guidance. DiFine UI is developed using <a style="color: #447ec9" href="https://www.uvicorn.org/">Uvicorn</a> and <a style="color: #447ec9" href="https://fastapi.tiangolo.com/">FastAPI</a>.
        </p>
      <p class="w3-justify">
          DiFine UI possesses 3 main functions: drawing, controlling, and diagnosis training. The drawing mode allows users to draw any medical images from sketches using different brushes. The control mode allows users to adjust the diagnosis parameters to control the synthesis. The diagnosis training allows users to practice and evaluate the diagnosis based on synthesized images, enabling educational applications.
        </p>
      <p class="w3-justify">
          Function 1. Drawing:
        </p>
        <p style="text-align:center;">
        <video style="width:60%;" class="video lazy" controls muted poster="videos/draw.png">
          <source src="videos/draw.MP4" type="video/mp4"></source>
        </video>
            </p>
      <p class="w3-justify">
          Function 2. Controlling:
        </p>
        <p style="text-align:center;">
        <video style="width:80%;" class="video lazy" controls muted poster="videos/control.png">
          <source src="videos/control.MP4" type="video/mp4"></source>
        </video>
        </p>
      <p class="w3-justify">
          Function 3. Diagnosis Training:
        </p>
        <p style="text-align:center;">
        <video style="width:80%;" class="video lazy" controls muted poster="videos/train.png">
          <source src="videos/train.MP4" type="video/mp4"></source>
        </video>
        </p>

        <hr class="divider" />

        <h3><li><strong>Thesis: Fast and Precise Lung CT Image Generation via Diffusion Models</strong> <a style="color: #447ec9" href="https://essay.utwente.nl/95061/">[Paper]</a></li></h3>
        <p class="w3-justify">
          Overview of the proposed model (Latent Semantic Diffusion Model, LSDM):
        </p>
        <img style="width:100%;" src="images/lsdm.png">
        <p class="w3-justify">
          Generation comparison of the lung CT scans between the proposed model and the popular SPADE model (notice the details of the lobes boundaries in the proposed model):
        </p>
        <img style="width:100%;" src="images/r2-best.png">
        <p class="w3-justify">
          Proposed inpainting classifier guidance for the controllability of the CT scan synthesis. The guidance scale is controllable to adjust the malignancy of the synthesized CT scans:
        </p>
      <p style="text-align:center;">
        <img style="width:80%;" src="images/r4-classifier-scales.png">
      </p>

        <hr class="divider" />

        <h3><li><strong>‘Tyrion’ -- the Extremely Tiny Industrial Manipulator</strong> <a style="color: #447ec9" href="https://github.com/zuxinrui/Tyrion">[Project Page]</a></li></h3>
        <img style="width:100%;" src="images/tyrion.png"> 
        <img style="width:100%;" src="images/tyrion-spec.png"> 
        <img style="width:100%;" src="images/tyrion-spec2.png"> 
<!--        <p class="w3-justify">-->
<!--        <a style="color: #447ec9" href="https://github.com/zuxinrui/Tyrion">Project Page</a>-->
<!--        </p>-->

        <hr class="divider" />

        <h3><li><strong>SpaceMAP</strong> <a style="color: #447ec9" href="https://proceedings.mlr.press/v162/zu22a.html">[Paper</a> | <a style="color: #447ec9" href="https://github.com/zuxinrui/SpaceMAP">Code]</a></li></h3>
        <img style="width:97%;" src="images/spacemap-intro.png"> 
        <img style="width:97%;" src="images/spacemap-thumb.png"> 
<!--        <p class="w3-justify">-->
<!--        <a style="color: #447ec9" href="https://proceedings.mlr.press/v162/zu22a.html">Paper</a> | <a style="color: #447ec9" href="https://github.com/zuxinrui/SpaceMAP">Code</a>-->
<!--        </p>-->
        <p class="w3-justify">
          We proposed a new visualization method called SpaceMAP, which visualizes data of any dimensionality on a 2- dimensional map. Different from previous DR methods, we analytically derived a transformation of distance between high- and low-dimensional spaces to match their capacity. We further show that the transformation provably reduces the intrinsic dimension of high-dimensional data, within the framework of maximum likelihood intrinsic dimensionality estimation.        </p> 
        </p>
        <p class="w3-justify">
          The following figure shows the result comparison with other methods:
        </p>
        <img style="width:100%;" src="images/spacemap-results.png">
      <p class="w3-justify">
          SpaceMAP optimization process as the "unrolling" of the Swiss Roll dataset:
        </p>
        <p class="w3-justify w3-center">
        <img style="width:50%;" src="images/spacemap-crop.gif">
        </p>

    <hr class="divider" />

        <h3><li><strong>Domain Adaptation of MRI Segmentation</strong></li></h3>
        <img style="width:100%;" src="images/mri.png"> 
        <p class="w3-justify">
          Since Sep. 2021, I work as a research assistant in the Department of Imaging Physics (ImPhys), TU Delft. My research topics include deep learning domain adaptation of the MRI segmentation tasks, MRI image processing and manifold learning.
        </p>
        <p class="w3-justify">
          Based on the observation of the organ-related cracks in the visualization of the neural network’s representation spaces (hidden layers’ outputs) for segmentation (UNet-like neural networks), I propose a visualization method of the cracks for evaluating the segmentation quality. I observe that UNet-like model tend to generate these cracks in the hidden layers based on the skip-connection mechanism.
        </p>

    <hr class="divider" />

        <h3><li><strong>Deep Recursive Embedding</strong><a style="color: #447ec9" href="https://ieeexplore.ieee.org/document/9585419">[Paper</a> | <a style="color: #447ec9" href="https://github.com/zuxinrui/DeepRecursiveEmbedding">Code]</a></li></h3>
        <img style="width:100%;" src="images/dre.png">
        <p class="w3-justify">
          We propose deep recursive embedding (DRE), a dimensionality reduction (DR) method to embed high-dimensional data into low-dimensional space (often into 2D space for visualization). DRE makes use of the latent data representations for boosted embedding performance and can map out-of-sample data and scale to extremely large datasets. Experiments on a range of public datasets demonstrated improved embedding performance in terms of local and global structure compared to the state-of-the-art methods.
        </p>
        <p class="w3-justify">
          The optimization process of the dimensionality reduction of MNIST dataset is shown in the GIF below:
        </p>
        <p class="w3-justify w3-center">
        <img style="width:77%;" src="images/MNIST-conv-2.gif">
        </p>

    <hr class="divider" />

        <h3><li><strong>ROS Autonomus Vehicle</strong></li></h3>
        <img style="width: 43%;" src="images/ros-v.jpg"> &nbsp&nbsp <img style="width: 54%;" src="images/ros-2.png">
        <p class="w3-justify">
          I designed a STM32 low-level controller for the ROS autonomus vehicle to control both the IMU and the motors. I built the ROS packages in Noetic version and deployed them into the RPi Ubuntu system. I used Gmapping SLAM algorithm to construct the maps.
        </p>

    <hr class="divider" />

        <h3><li><strong>'SmartArm' -- A Reconfigurable Modular Manipulator </strong><a style="color: #447ec9" href="https://github.com/zuxinrui/Smartarm">[Project Page]</a></li></h3>
        <img style="width: 49%;" src="images/smartarm2.gif"> &nbsp <img style="width: 49%;" src="images/smartarm2_tra.gif">
        <p class="w3-justify">
          SmartArm is a series of reconfigurable modular robotic manipulators using full closed-loop perception control and adaptive control to achieve the same repeatability with much more expensive robotic manipulators. Using multi-sensor system and removable structure, it will adapt to multi-environment tasks. Smartarm is fully built by my own and I will do further research based on this platform. Smartarm uses ROS noetic as the middleware and the physical structure was designed through Fusion 360 Autodesk.
        </p>
        <p class="w3-justify">
          Combined with my project Ultrasonic Localization System, SmartArm has a full closed-loop controller with two end-effector localization modes: fast response mode (FRM) and smooth response mode (SRM). The first GIF above (left) shows the reaction speed test of `end effector tracking` with SmartArm's sonic localization system, which is illustrated in the next section. The second GIF on the right shows Smartarm's `motion planning & execute` pipeline using `MoveIt!` with my own asynchronous adjustments (SmartArm can adapt new trajactories while executing to follow the target). I also created a `MoveIt!` function called `asyncPlanAndMove()` after changing `MoveIt!` source code to reach my planning goal.
        </p>
        <h4>SmartArm Controller</h4>
        <p class="w3-justify w3-center">
          <img style="width: 57%;" src="images/afc.png">
        </p>
        <p class="w3-justify">
          Currently I am developing a real-time dynamic controller of Smartarm. It transits the position signal generated by the main compute unit (Linux) into force signal (joint space). I used adaptive feedforwared control (AFC) to learn the dynamic parameter of the manipulator. For some repeatable tasks like pick and place, I will also develop iterative learning control (ILC) to improve control accuracy.
        </p>
        <h4>SmartArm with MoveIt!</h4>
        <p class="w3-justify">
          I also developed a MoveIt! simulation&control environment for Smartarm. I developed my own MoveIt! `move_group` function to fit the motion planning algorithm. The function `move()` in MoveAction's client has been adjusted as `smartarm_move` to fulfill the fast generation of the trajectory.
        </p>
        <p class="w3-justify w3-center">
          <img style="width: 77%;" src="images/smartarm_track.png">
        </p>
        <p class="w3-justify">
          The structure above shows Smartarm's MoveIt! functions w.r.t. sensor system and the main control loop. I will continue to develop the low-level real-time controller to improve the performance of Smartarm.
        </p>

    <hr class="divider" />

        <h3><li><strong>Ultrasonic Localization System</strong></li></h3>
        <img style="width: 40%;" src="images/sonic.png"> &nbsp&nbsp&nbsp <img style="width: 57%;" src="images/sonic-local.gif">
        <p class="w3-justify">
          I combined my previous sonic localization system and IMU together with `extended Kalman Filtering`. The accuracy of the localization is now about 0.5mm in xyz axis and about 0.01rad in 3 rotation axis.
        </p>
        <p class="w3-justify">
          This sensor system uses `STM32F103RCT6` as the control unit. I developed `DMA(direct memory access)` and `hardware boosting` to calculate the sensors' data faster. The sampling rate is 1000Hz.
        </p>

    <hr class="divider" />

        <h3><li><strong>Fudan University National College Science Camp</strong></li></h3>
        <img style="width: 49%;" src="images/camp1.png"> &nbsp <img style="width: 49%;" src="images/camp2.png">
        <p class="w3-justify">
          When I was at Fudan university, I was the host and also the lecturer of every year's National Youth University Science Camp. In 2019's Science Camp, I developed a ROS mobile platform with `Raspberry Pi 3B` as the main controller. The vehicle used lidar as the input and used ROS `gmapping` package for SLAM algorithm.
        </p>
        <p class="w3-justify">
          In the lecture called `Basic robotics: from theory to practice`, I used this as the tutorial platform and train 100 students the basic SLAM implementing and ROS programming. It was an interesting experience with all the students from high school who brought much curiosity to the workshop. Hope them dive into the fantastic robot world!
        </p>

<!--         <h3><li>UAV Interceptor</li></h3>
        <img style="width: 32%;" src="images/uav1.png"> <img style="width: 67%;" src="images/uav2.png">
        <p class="w3-justify">
          This is the product of Denghui Project at Fudan University. This low-cost, high speed Micro-UAV interceptor has an available distance about 500m. Within this distance, it can catch most of quadrotors in the market. The aerocraft structure is developed by my own.
        </p>
        <h4>Anti-UAV Design</h4>
        <img style="width: 100%;" src="images/uav3.png">
        <p class="w3-justify">
          During the design procedure, I iterated the aerocraft structure design many times in order to fit the requirements of limited space, material strength, strike distance, low-weight and other practical requirements. The most significant problem is the extremely compact space. I developed a innovative structure to make the system functional in a very limited space (the diameter of the missile-like aerocraft is only 40mm).
        </p>
        <h4>UAV Interceptor Experiments</h4>
        <img style="width: 100%;" src="images/uav4.png">
        <p class="w3-justify">
          I launched this tiny 'missile' in Fudan campus and the passersby were frightened in a way or another :P. I flied a target quadrotor and the 'missile' brought me back the poor quadrotor, only with many pieces.
        </p> -->

      <hr class="divider" />

        <h3><li><strong>3Arobot</strong></li></h3>
        <img style="width: 100%;" src="images/3a.png">
        <p class="w3-justify">
          3Arobot is a series of robotic manipulators printed by the 3D printers. These manipulators have competitive accuracies and repeatabilities. They have the ability to write and draw on a paper with certain end effectors. Furthermore, with a heating extruder, they can be used as 3D printers.
        </p>

  </div>
  
  <!-- The Talks Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="talks">
    <h2>Talks</h2>
      <p><li> 07/2022, SpaceMAP: Visualizing High-dimensional Data by Space Expansion at <a href="https://icml.cc/virtual/2022/poster/18169">ICML 2022, Baltimore, US</a>.</li></p>
  </div>
 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32" id="publications">
    <h2>Publications</h2>
    <h4> Conference Papers:</h4>

    <ol>

        <p>
      <li><strong>cHeartFlow: Synthesizing cardiac MR images from sketches</strong>
      <br>
      <strong>X. Zu</strong>, Q. Tao
      <br>
      <em>MIDL</em> 2024 | <a style="color: #447ec9" href="https://openreview.net/forum?id=orIWvvBK2v">Paper</a>
      </p>

      <p>
      <li><strong>SpaceMAP: Visualizing High-dimensional Data by Space Expansion</strong>
      <br>
      <strong>X. Zu</strong>, Q. Tao
      <br>
      <em>ICML</em> 2022 | <a style="color: #447ec9" href="https://proceedings.mlr.press/v162/zu22a.html">Paper</a> | <a style="color: #447ec9" href="https://github.com/zuxinrui/SpaceMAP">Code</a>
      </p>

      <p>
      <li><strong>AI Analysis for low-field CMR: A head-to-head comparison of cine MRI at 0.35T, 1.5T, and 3.0T</strong>
      <br>
      <strong>X. Zu</strong>, J. Varghese, O. Simonetti, Q. Tao
      <br>
      <em>SCMR</em> 2022 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/document/9585419">Paper</a>
      </p>

    </ol>

      <h4> Journal Papers:</h4>

      <ol>

      <p>
          <li><strong>Deep Recursive Embedding for High-Dimensional Data</strong>
          <br>
          Z. Zhou, <strong>X. Zu</strong>, Y. Wang, B. P. F. Lelieveldt, Q. Tao
          <br>
          <em>IEEE TVCG</em> 2022 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/document/9585419">Paper</a> | <a style="color: #447ec9" href="https://github.com/zuxinrui/DeepRecursiveEmbedding">PyTorch Code</a>
      </p>

      </ol>

      <h4> Thesis:</h4>

        <ol>
            <p>
              <li><strong>Fast and Precise Lung CT Image Generation via Diffusion Models</strong> <a style="color: #447ec9" href="https://essay.utwente.nl/95061/">Paper</a>
              </p>
        </ol>

    </p>
  </div>

  <!-- The Awards Section -->
<!--  <div class="w3-container w3-padding-32" id="award">-->
<!--    <h2>Awards</h2>-->
<!--    <p><li> 2018, Best Popularity Project in Fudan Hackathon, Fudan University</p>-->
<!--    <p><li> 2018, 3rd Prize of China College Students’ Entrepreneurship Competition</p>-->
<!--    <p><li> 2018, Scholarship for Excellent Undergraduates, Fudan University</p>-->
<!--    <p><li> 2017, Scholarship for Excellent Undergraduates, Fudan University</p>-->
<!--    <p><li> 2016, Scholarship for Excellent Undergraduates, Fudan University</p>-->
<!--  </div>  -->

  <div class="w3-light-grey w3-center w3-padding-24">

    Welcome to use this website's <a href="https://github.com/YunheWang/HomePage">source code</a>, just add a link back to here. <a href="https://www.wangyunhe.site/">&#10025;</a></br>

  <!-- Default Statcounter code for Yunhe Wang's Homepage
  https://www.wangyunhe.site -->
  No.
  <script type="text/javascript">
  var sc_project=12347113; 
  var sc_invisible=0; 
  var sc_security="21aca5d1"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since Feb 2022. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript>
    <div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12347113/0/21aca5d1/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
